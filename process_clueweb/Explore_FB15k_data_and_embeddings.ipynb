{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import cPickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tsne import bh_sne\n",
    "import mpld3\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sys.path.append(\"/Users/corbinrosset/Dropbox/Arora/QA-code/src/\")\n",
    "\n",
    "import KBC_Text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapath = '/Users/corbinrosset/Dropbox/Arora/QA-code/src/KBC_Text/data/'\n",
    "dataset = 'FB15k'\n",
    "relation_key_words = set(['film', 'government', 'tv', 'location', 'organization', \\\n",
    "                          'education', 'award', 'football', 'people', 'olympics', \\\n",
    "                          'music', 'military', 'popstra', 'business', 'baseball', 'NotFound'])\n",
    "entity_key_words = set(['film', 'university', 'award', 'county', 'football', 'team', 'city', 'national', 'actor', \\\n",
    " 'congress', 'england', 'history', 'performance', 'california', 'war', 'america', \\\n",
    "  'Party', 'Basketball', 'tv', 'france', 'King', 'NotFound'])\n",
    "\n",
    "# set(['film', 'sports', 'government', 'tv', 'location', 'organization', 'education', \\\n",
    "#  'award', 'football', 'people', 'olympics', 'team', 'music', \\\n",
    "#  'military', 'popstra', 'business', 'baseball', \\\n",
    "#  'player', 'position', 'fictional_universe', \\\n",
    "#  'basketball', 'measurement_unit', 'soccer', 'currency', 'person', \\\n",
    "#  'religion', 'medicine', 'computer', 'ice_hockey', 'money', 'book', \\\n",
    "#  'travel', 'aviation', 'broadcast', 'country', 'actor', 'roster', 'NotFound'])\n",
    "\n",
    "def load_file(path):\n",
    "    return scipy.sparse.csr_matrix(cPickle.load(open(path)),\n",
    "            dtype=np.float64)\n",
    "\n",
    "\n",
    "def convert2idx(spmat):\n",
    "    rows, cols = spmat.nonzero()\n",
    "    return rows[np.argsort(cols)]\n",
    "\n",
    "\n",
    "def load_FB15k_data():\n",
    "    # Positives\n",
    "    trainl = load_file(datapath + dataset + '-train-lhs.pkl') # rows = entities, col are one hot to indicate which is left entity\n",
    "    trainr = load_file(datapath + dataset + '-train-rhs.pkl') # rows = relations, but only in bottom 1,345 rows\n",
    "    traino = load_file(datapath + dataset + '-train-rel.pkl')\n",
    "\n",
    "#     print trainl.tocoo()\n",
    "    print traino.tocsc()\n",
    "\n",
    "    \n",
    "    # Valid set\n",
    "    validl = load_file(datapath + dataset + '-valid-lhs.pkl')\n",
    "    validr = load_file(datapath + dataset + '-valid-rhs.pkl')\n",
    "    valido = load_file(datapath + dataset + '-valid-rel.pkl')\n",
    "#     print np.shape(validl)\n",
    "\n",
    "\n",
    "    # Test set\n",
    "    testl = load_file(datapath + dataset + '-test-lhs.pkl')\n",
    "    testr = load_file(datapath + dataset + '-test-rhs.pkl')\n",
    "    testo = load_file(datapath + dataset + '-test-rel.pkl')\n",
    "    \n",
    "\n",
    "    # create list of which rows were hot for each of the 483k columns (each column is one hot)\n",
    "    trainlidx = convert2idx(trainl) # extract the first neval left entity examples (just take which row is hot in trainl)\n",
    "    trainridx = convert2idx(trainr)\n",
    "    trainoidx = convert2idx(traino) # take the rows that are hot in the first neval columns of traino\n",
    "    validlidx = convert2idx(validl)\n",
    "    validridx = convert2idx(validr)\n",
    "    validoidx = convert2idx(valido)\n",
    "    testlidx = convert2idx(testl)\n",
    "    testridx = convert2idx(testr)\n",
    "    testoidx = convert2idx(testo)\n",
    "    print np.shape(trainlidx)\n",
    "    print np.shape(trainridx)\n",
    "    print np.shape(trainoidx)\n",
    "    \n",
    "    true_triples=np.concatenate([testlidx,validlidx,trainlidx,testoidx,validoidx,trainoidx,testridx,validridx,trainridx]).reshape(3,testlidx.shape[0]+validlidx.shape[0]+trainlidx.shape[0]).T\n",
    "    KB = set([tuple(i) for i in true_triples]) ### {(head, rel, tail)}\n",
    "    assert len(KB) == np.shape(true_triples)[0]\n",
    "    \n",
    "    return trainlidx, trainridx, trainoidx, validlidx, validridx, validoidx, testlidx, testridx, testoidx, true_triples, KB\n",
    "        \n",
    "def load_embeddings(path):\n",
    "    print'loading model from file: ' + str(path)\n",
    "    embeddings = cPickle.load(open(path))\n",
    "    ### TODO: write the word embeddings to file as well\n",
    "    entityEmbs, relEmbsL, relEmbsR = embeddings[0].E.get_value().T, embeddings[2].E.get_value().T, embeddings[2].E.get_value().T\n",
    "    return entityEmbs, relEmbsL, relEmbsR\n",
    "\n",
    "def t_sne(data):\n",
    "    '''run_bh_tsne(data, no_dims=2, perplexity=50, theta=0.5, randseed=-1, verbose=False,initial_dims=50, use_pca=True, max_iter=1000):\n",
    "        \n",
    "        Run TSNE based on the Barnes-HT algorithm\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        data: file or numpy.array\n",
    "            The data used to run TSNE, one sample per row\n",
    "        no_dims: int\n",
    "        perplexity: int\n",
    "        randseed: int\n",
    "        theta: float\n",
    "        initial_dims: int\n",
    "        verbose: boolean\n",
    "        use_pca: boolean\n",
    "        max_iter: int\n",
    "    '''\n",
    "\n",
    "    X_2d = bh_sne(data, perplexity=40, theta=0.5) #, max_iter=600) #bh_sne(X, perplexity=50, theta=0.5)  \n",
    "    return X_2d\n",
    "\n",
    "def tooltip_style(text):\n",
    "    return \"<p style=\\\"color: #ffffff; background-color: #000000\\\">\" + str(text) + \"</p>\"\n",
    "\n",
    "def get_label_rel(relation):\n",
    "    for i in relation_key_words:\n",
    "        if i in str(relation):\n",
    "            return i\n",
    "    return 'NotFound'\n",
    "\n",
    "def get_label_ent(entity):\n",
    "    entity_key_words\n",
    "    for i in entity_key_words:\n",
    "        if i in str(entity.lower()):\n",
    "            return i\n",
    "    return 'NotFound'\n",
    "    \n",
    "    \n",
    "def plot_embeddings(X, Y, popup_labels, title):\n",
    "    '''X is a list of matrices of length n, each of which has its own class or \n",
    "    color, y. popup_labels is also a list of n lists, each containing the tag\n",
    "    of individual points (rows in a matrix of X)'''\n",
    "\n",
    "    ###############\n",
    "    labels_set = set(entity_key_words).copy() ### change THIS for relation/entities\n",
    "    labels_set.remove('NotFound')\n",
    "    \n",
    "    legend_partition, legend_strings = [], [] \n",
    "    l_keys, l_nums, recs = [], [], []\n",
    "    fig, ax = plt.subplots(subplot_kw=dict(axisbg='#EEEEEE'), figsize=(20,20))\n",
    "    \n",
    "    assert len(X) == len(Y)\n",
    "    if popup_labels:\n",
    "        assert len(popup_labels) == len(X)\n",
    "        assert np.shape(X)[0] == np.shape(popup_labels)[0]\n",
    "    ax.grid(color='white', linestyle='solid')\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(labels_set)))\n",
    "    color_label_map = {}\n",
    "    for c, label in zip(colors, labels_set):\n",
    "        color_label_map[label] = c\n",
    "        legend_strings.append(label)\n",
    "        \n",
    "    for (x, group_label, tag) in zip(X, Y, popup_labels):\n",
    "        # label = get_label_rel(tag) # Change THIS\n",
    "        label = get_label_ent(tag)\n",
    "        if label == 'NotFound':\n",
    "            continue\n",
    "        scatter = ax.scatter(x[0], x[1], c = color_label_map[label], alpha=1.0, label=label)\n",
    "        legend_partition.append(scatter)\n",
    "        tooltip = mpld3.plugins.PointHTMLTooltip(scatter, labels=[tooltip_style(tag)])\n",
    "        mpld3.plugins.connect(fig, tooltip)\n",
    "        \n",
    "    print 'Legend: '\n",
    "    for i, (key, value) in enumerate(color_label_map.items()):\n",
    "        print str(i) + ' = ' + str(key)\n",
    "        l_nums.append(str(i))\n",
    "        l_keys.append(key)\n",
    "        recs.append(mpatches.Rectangle((0,0),1,1,fc=value))\n",
    "\n",
    "    plt.legend(recs, l_keys, loc='upper right', fontsize=8)\n",
    "    if title:\n",
    "        ax.set_title(title, size=12)\n",
    "        \n",
    "    mpld3.save_html(fig, title + '.html')\n",
    "    mpld3.show()\n",
    "#     mpld3.display() # doesn't seem to work for ipython notebooks?\n",
    "    return\n",
    "\n",
    "def plot_embedding_pairs(X1, X2, Y, popup_labels, title):\n",
    "    '''X is a list of matrices of length n, each of which has its own class or \n",
    "    color, y. popup_labels is also a list of n lists, each containing the tag\n",
    "    of individual points (rows in a matrix of X)'''\n",
    "\n",
    "    ###############\n",
    "    labels_set = set(relation_key_words).copy() ### change THIS for relation/entities\n",
    "    labels_set.remove('NotFound')\n",
    "    \n",
    "    legend_partition, legend_strings = [], [] \n",
    "    l_keys, l_nums, recs = [], [], []\n",
    "    fig, ax = plt.subplots(subplot_kw=dict(axisbg='#EEEEEE'), figsize=(20,20))\n",
    "    \n",
    "    assert len(X) == len(Y)\n",
    "    if popup_labels:\n",
    "        assert len(popup_labels) == len(X)\n",
    "        assert np.shape(X)[0] == np.shape(popup_labels)[0]\n",
    "    ax.grid(color='white', linestyle='solid')\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(labels_set)))\n",
    "    color_label_map = {}\n",
    "    for c, label in zip(colors, labels_set):\n",
    "        color_label_map[label] = c\n",
    "        legend_strings.append(label)\n",
    "        \n",
    "    for (x1, x2, group_label, tag) in zip(X1, X2, Y, popup_labels):\n",
    "        label = get_label_rel(tag) # Change THIS\n",
    "#         label = get_label_ent(tag)\n",
    "        if label == 'NotFound':\n",
    "            continue\n",
    "        scatter = ax.scatter([x1[0], x2[0]], [x1[1], x2[1]], c = color_label_map[label], alpha=1.0, label=label)\n",
    "        plt.plot([x1[0], x2[0]], [x1[1], x2[1]], color=\"black\", linewidth=0.1)\n",
    "        legend_partition.append(scatter)\n",
    "        tooltip = mpld3.plugins.PointHTMLTooltip(scatter, labels=[tooltip_style(tag)])\n",
    "        mpld3.plugins.connect(fig, tooltip)\n",
    "        \n",
    "    print 'Legend: '\n",
    "    for i, (key, value) in enumerate(color_label_map.items()):\n",
    "        print str(i) + ' = ' + str(key)\n",
    "        l_nums.append(str(i))\n",
    "        l_keys.append(key)\n",
    "        recs.append(mpatches.Rectangle((0,0),1,1,fc=value))\n",
    "\n",
    "    plt.legend(recs, l_keys, loc='upper right', fontsize=8)\n",
    "    if title:\n",
    "        ax.set_title(title, size=12)\n",
    "        \n",
    "    mpld3.save_html(fig, title + '.html')\n",
    "    mpld3.show()\n",
    "#     mpld3.display() # doesn't seem to work for ipython notebooks?\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (15742, 0)\t1.0\n",
      "  (16224, 1)\t1.0\n",
      "  (15797, 2)\t1.0\n",
      "  (15046, 3)\t1.0\n",
      "  (16051, 4)\t1.0\n",
      "  (16119, 5)\t1.0\n",
      "  (15683, 6)\t1.0\n",
      "  (15550, 7)\t1.0\n",
      "  (16049, 8)\t1.0\n",
      "  (15506, 9)\t1.0\n",
      "  (15037, 10)\t1.0\n",
      "  (15028, 11)\t1.0\n",
      "  (15921, 12)\t1.0\n",
      "  (15041, 13)\t1.0\n",
      "  (15919, 14)\t1.0\n",
      "  (15886, 15)\t1.0\n",
      "  (15031, 16)\t1.0\n",
      "  (15545, 17)\t1.0\n",
      "  (15978, 18)\t1.0\n",
      "  (15050, 19)\t1.0\n",
      "  (15546, 20)\t1.0\n",
      "  (15534, 21)\t1.0\n",
      "  (15041, 22)\t1.0\n",
      "  (15860, 23)\t1.0\n",
      "  (15755, 24)\t1.0\n",
      "  :\t:\n",
      "  (15978, 483117)\t1.0\n",
      "  (15917, 483118)\t1.0\n",
      "  (15045, 483119)\t1.0\n",
      "  (15864, 483120)\t1.0\n",
      "  (16039, 483121)\t1.0\n",
      "  (15578, 483122)\t1.0\n",
      "  (15871, 483123)\t1.0\n",
      "  (15167, 483124)\t1.0\n",
      "  (15889, 483125)\t1.0\n",
      "  (15137, 483126)\t1.0\n",
      "  (15049, 483127)\t1.0\n",
      "  (15798, 483128)\t1.0\n",
      "  (15335, 483129)\t1.0\n",
      "  (15576, 483130)\t1.0\n",
      "  (15710, 483131)\t1.0\n",
      "  (15978, 483132)\t1.0\n",
      "  (15545, 483133)\t1.0\n",
      "  (15869, 483134)\t1.0\n",
      "  (16043, 483135)\t1.0\n",
      "  (15049, 483136)\t1.0\n",
      "  (15037, 483137)\t1.0\n",
      "  (15042, 483138)\t1.0\n",
      "  (15051, 483139)\t1.0\n",
      "  (15981, 483140)\t1.0\n",
      "  (15802, 483141)\t1.0\n",
      "(483142,)\n",
      "(483142,)\n",
      "(483142,)\n"
     ]
    }
   ],
   "source": [
    "trainlidx, trainridx, trainoidx, validlidx, validridx, validoidx, \\\n",
    "testlidx, testridx, testoidx, true_triples, KB = load_FB15k_data()\n",
    "\n",
    "entity2idx = cPickle.load(open(datapath + dataset + '_entity2idx.pkl'))\n",
    "idx2entity = dict([(j, i) for (i, j) in entity2idx.items()])\n",
    "entity2name = cPickle.load(open(datapath + dataset + '_idx2entityname'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# entity2name, FB15k_ents = {}, set(entity2idx.keys())\n",
    "# with open(datapath + 'FBmid_to_name.tsv') as f:\n",
    "#     for line in f:\n",
    "#         line = line.strip().split('\\t')\n",
    "#         mid, name = line[0], line[1]\n",
    "#         if mid in FB15k_ents:\n",
    "#             entity2name[entity2idx[mid]] = name\n",
    "# print len(entity2name)\n",
    "# print entity2name\n",
    "# with open(datapath + dataset + '_idx2entityname', 'w') as f:\n",
    "#     cPickle.dump(entity2name, f, -1)\n",
    "# entity2name = cPickle.load(open(datapath + dataset + '_idx2entityname'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### histogram of test relation occurance\n",
    "print len(testoidx)\n",
    "relsids = testoidx - 14951\n",
    "print len(idx2entity)\n",
    "# print idx2entity\n",
    "relnames = [idx2entity[i] for i in testoidx]\n",
    "# cntr = Counter(relnames)\n",
    "plt.hist(relsids, bins=1345)\n",
    "plt.xlabel('relation id')\n",
    "plt.ylabel('Number of test triples expressing the rel id')\n",
    "plt.title('Histogram of the Occurance of Relation in FB15k Test Data')\n",
    "plt.show()\n",
    "# print cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### histogram of train relation occurance\n",
    "print len(trainoidx)\n",
    "relsids = trainoidx - 14951\n",
    "relnames = [idx2entity[i] for i in trainoidx]\n",
    "# cntr = Counter(relnames)\n",
    "plt.hist(relsids, bins=1345)\n",
    "plt.xlabel('Relation ID')\n",
    "plt.ylabel('Number of Train Triples Expressing the Relation ID')\n",
    "plt.title('Histogram of the Occurance of Relation in FB15k Train Data')\n",
    "plt.show()\n",
    "# print cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### get categories of relationships\n",
    "# path = '/Users/corbinrosset/Dropbox/Arora/QA-code/src/KBC_Text/outputs/FB15k_TransE/BEST_TransE_L1_ndim_100_marg_1.5_lrate_0.01_cost_margincost_reg_0.01_REL/'\n",
    "# entyEmbs, relEmbs = load_embeddings(path + 'best_valid_model.pkl')\n",
    "# relnames = [str(idx2entity[i+14951]) for i in range(len(relEmbs))]\n",
    "# words = [i for j in relnames for i in j.strip().split('/') if len(i) > 0]\n",
    "# print len(words)\n",
    "# cntr = Counter(words)\n",
    "# # print cntr.most_common(100)\n",
    "# print map(lambda (x, y): x, filter(lambda (name, count) : count > 50, cntr.most_common(1000)))\n",
    "\n",
    "### get categories of entities\n",
    "# words = [i for j in entity2name.values() for i in j.strip().split()]\n",
    "# print len(words)\n",
    "# cntr = Counter(words)\n",
    "# # print cntr.most_common(100)\n",
    "# print map(lambda (x, y): x, filter(lambda (name, count) : count > 20, cntr.most_common(1000)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from file: /Users/corbinrosset/Dropbox/Arora/QA-code/src/KBC_Text/outputs/FB15k_BilinearDiagExtended/BilinearDiagExtended_L1_ndim_200_marg_0.2_lrate_0.01_cost_margincost_pos_high_reg_0.01/best_valid_model.pkl\n",
      "(16296, 200) (1345, 200)\n",
      "(59071,)\n",
      "[ 0.          0.58295835  0.81580105  1.02205984  1.25977066  1.45958476\n",
      "  1.71706667  1.93378204  2.2669627   2.49077724]\n",
      "[ 0.18190672  0.65344461  0.83380231  1.02839852  1.19150549  1.35639841\n",
      "  1.51422798  1.6795864   1.89328461  2.07296602]\n"
     ]
    }
   ],
   "source": [
    "###  T-SNE plot of entity embeddings from various models\n",
    "base = '/Users/corbinrosset/Dropbox/Arora/QA-code/src/KBC_Text/outputs/'\n",
    "# model = 'FB15k_TransE/BEST_TransE_L1_ndim_100_marg_1.5_lrate_0.01_cost_margincost_reg_0.01_REL'\n",
    "model = 'FB15k_BilinearDiagExtended/BilinearDiagExtended_L1_ndim_200_marg_0.2_lrate_0.01_cost_margincost_pos_high_reg_0.01'\n",
    "# model = 'FB15k_BilinearDiag/BEST_BilinearDiag_Dot_ndim_100_marg_0.2_lrate_0.01_cost_margincost_pos_high_reg_0.01_REL'\n",
    "# model = 'FB15k_Bilinear/BEST_Bilinear_Dot_ndim_50_marg_0.2_lrate_0.01_cost_margincost_pos_high_reg_0.01_REL'\n",
    "# model = 'FB15k_ModelE/BEST_ModelE_Sum_ndim_100_marg_1.0_lrate_0.01_cost_margincost_pos_high_reg_0.01_REL'\n",
    "\n",
    "entyEmbs, relEmbsL, relEmbsR = load_embeddings(base + model + '/best_valid_model.pkl')\n",
    "print np.shape(entyEmbs), np.shape(relEmbsL)\n",
    "\n",
    "####################################### relations\n",
    "# X_2d = t_sne(relEmbsL) #\n",
    "# print 'done with tsne ' + str(np.shape(X_2d))\n",
    "# popup_labels = [str(idx2entity[i+14951]) for i in range(len(relEmbsL))]\n",
    "# plot_embeddings(X_2d, range(len(relEmbsL)), popup_labels, 'T-SNE plot of Tail Relation Embeddings for ' + model.split('/')[-1])\n",
    "         \n",
    "####################################### 2-way relations\n",
    "# testlidx = testlidx[:1000]\n",
    "# testoidx = testoidx[:1000]\n",
    "# testridx = testridx[:1000]\n",
    "X1 = np.multiply(entyEmbs[testlidx, :], relEmbsL[(testoidx-14951), :])\n",
    "X2 = np.multiply(entyEmbs[testridx, :], relEmbsR[(testoidx-14951), :])\n",
    "X2_rand = np.multiply(entyEmbs[testridx, :], relEmbsR[np.random.randint(0, high=1345, size=np.shape(testoidx)), :]) \n",
    "######### stop here for a second\n",
    "X_L1dist = np.linalg.norm(X1 - X2, 1, axis = 1)\n",
    "X_L1dist_random = np.linalg.norm(X1 - X2_rand, 1, axis = 1)\n",
    "\n",
    "print np.shape(X_L1dist)\n",
    "# print X_L1dist\n",
    "print np.percentile(X_L1dist, range(0, 100, 10))\n",
    "print np.percentile(X_L1dist_random, range(0, 100, 10))\n",
    "\n",
    "######## resume here:\n",
    "# n = np.shape(X1)[0]\n",
    "# print np.shape(X1), np.shape(X2)\n",
    "# X = np.vstack([X1, X2])\n",
    "# popup_labels = [str(idx2entity[i]) for i in testoidx] * 2\n",
    "# labels = [1 for i in testoidx] + [2 for i in testoidx] # list(testoidx)*2\n",
    "# assert X.shape[0] == len(popup_labels)\n",
    "\n",
    "# X_2d = t_sne(X) #\n",
    "# print 'done with tsne ' + str(np.shape(X_2d))\n",
    "# plot_embedding_pairs(X_2d[:n, :], X_2d[n:, :], labels, popup_labels, 'T-SNE plot of Tail Relation Embeddings for ' + model.split('/')[-1])\n",
    "      \n",
    "    \n",
    "####################################### entities\n",
    "# X_2d = t_sne(entyEmbs) #\n",
    "# print 'done with tsne ' + str(np.shape(X_2d))\n",
    "# popup_labels = [str(entity2name.get(i, 'unknown')) for i in range(len(entyEmbs))]\n",
    "# plot_embeddings(X_2d, range(len(entyEmbs)), popup_labels, 'T-SNE plot of Entity Embeddings for ' + model.split('/')[-1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
